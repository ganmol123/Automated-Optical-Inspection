{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "aoi_summer_begin.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q7hp6EL0rDf4"
      },
      "source": [
        "# Step 1: upload the folder AUAOI to your google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uEHrJ5lVQMcB",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ApdziUlE2EY",
        "colab": {}
      },
      "source": [
        "PATH = \"drive/My Drive/AUAOI\"\n",
        "!ls \"drive/My Drive/AUAOI\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2FpHSBYimPN",
        "colab_type": "text"
      },
      "source": [
        "# Step 2: Using Sikit-learn and Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wSE-KUByPPaE",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "from keras.layers import merge, Input\n",
        "from keras.models import Model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9W4ufCeyDlui"
      },
      "source": [
        "# Step 3: Read images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aPbF9XngPPaJ",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "#Setting data path\n",
        "#Read the file names in the folder directory\n",
        "### START CODE HERE ###  (≈ 2 lines)\n",
        "\n",
        "### END CODE HERE ###\n",
        "\n",
        "#設定一個list\n",
        "img_data_list=[]\n",
        "\n",
        "#Read images under the folders with loops \n",
        "### START CODE HERE ###  (≈ 5 lines)\n",
        "\n",
        "### END CODE HERE ###\n",
        "    \n",
        "    #Read the image \n",
        "    #Convert the image to array \n",
        "    #Add the dimension to the front of the array \n",
        "    #Preprocess_input\n",
        "    #Save the array to the list\n",
        "    ### START CODE HERE ###  (≈ 5 lines)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "img_data = np.array(img_data_list)\n",
        "\n",
        "print (img_data.shape)  #(600, 1, 224, 224, 3)\n",
        "img_data=np.rollaxis(img_data,1,0)\n",
        "print (img_data.shape)  #(1, 600, 224, 224, 3)\n",
        "img_data=img_data[0]\n",
        "print (img_data.shape)  #(600, 224, 224, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zczeM8iPimPX",
        "colab_type": "text"
      },
      "source": [
        "# Step 4: Labeling the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pG2D4U7_PPaN",
        "colab": {}
      },
      "source": [
        "# Labeling the images\n",
        "### START CODE HERE ###  (≈ 3 lines)\n",
        "\n",
        "### END CODE HERE ###\n",
        "\n",
        "labels[0:100]=0\n",
        "labels[100:200]=1\n",
        "labels[200:300]=2\n",
        "labels[300:400]=3\n",
        "labels[400:500]=4\n",
        "labels[500:600]=5\n",
        "\n",
        "# one-hot encoding\n",
        "###  CODE HERE ###  (≈ 1 lines)\n",
        "\n",
        "\n",
        "#Shuffling dataset\n",
        "###  CODE HERE ###  (≈ 1 lines)\n",
        "\n",
        "\n",
        "# Split images into training set and test set\n",
        "###  CODE HERE ###  (≈ 1 lines)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U-eheqIimPb",
        "colab_type": "text"
      },
      "source": [
        "# Step5: Customize VGG16 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bRH-lm84PPaP",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "#input shape\n",
        "###  CODE HERE ###  (≈ 1 lines)\n",
        "\n",
        "#Use the VGG16 model \n",
        "###  CODE HERE ###  (≈ 1 lines)\n",
        "\n",
        "\n",
        "#Summary of the customize VGG16 model\n",
        "###  CODE HERE ###  (≈ 1 lines)\n",
        "\n",
        "\n",
        "\n",
        "last_layer = model.get_layer('fc2').output\n",
        "out = Dense(num_classes, activation='softmax', name='output')(last_layer)\n",
        "custom_vgg_model = Model(image_input, out)\n",
        "custom_vgg_model.summary()\n",
        "\n",
        "for layer in custom_vgg_model.layers[:-1]:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "#Set the model's loss function, optimizer, and metrics\n",
        "###  CODE HERE ###  (≈ 1 lines)\n",
        "\n",
        "t=time.time()\n",
        "#The parameters for the training model\n",
        "###  CODE HERE ###  (≈ 1 lines)\n",
        "\n",
        "print('Training time: %s' % time.time())\n",
        "\n",
        "#Assess the accuracy of the trained model to the test data\n",
        "###  CODE HERE ###  (≈ 1 lines)\n",
        "\n",
        "\n",
        "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\n",
        "\n",
        "#Preditction of the test dataset\n",
        "#Print out the predicted Label value\n",
        "### START CODE HERE ###  (≈ 5 lines)\n",
        "\n",
        "### END CODE HERE ###\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tw3HIqSKHe1x"
      },
      "source": [
        "# Step 6: Output loss and accuracy figures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F2uzapglPPaS",
        "colab": {}
      },
      "source": [
        "Read 60 images in AOIdata_test and use trained models for prediction#%%\n",
        "# %matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "# visualizing losses and accuracy\n",
        "train_loss=hist.history['loss']\n",
        "val_loss=hist.history['val_loss']\n",
        "train_acc=hist.history['acc']\n",
        "val_acc=hist.history['val_acc']\n",
        "xc=range(10)\n",
        "\n",
        "plt.figure(1,figsize=(7,5))\n",
        "plt.plot(xc,train_loss)\n",
        "plt.plot(xc,val_loss)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('train_loss vs val_loss')\n",
        "plt.grid(True)\n",
        "plt.legend(['train','val'])\n",
        "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "plt.style.use(['classic'])\n",
        "\n",
        "plt.figure(2,figsize=(7,5))\n",
        "plt.plot(xc,train_acc)\n",
        "plt.plot(xc,val_acc)\n",
        "plt.xlabel('num of Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('train_acc vs val_acc')\n",
        "plt.grid(True)\n",
        "plt.legend(['train','val'],loc=4)\n",
        "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "plt.style.use(['classic'])\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "thyNqL64GVTk"
      },
      "source": [
        "# Exercise: \n",
        "Read 60 images in AOIdata_test and use trained models for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GgFbliJBGp6i",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}